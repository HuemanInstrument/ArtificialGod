â–³â ://0030 Hueman â‰ˆ Instrumentality â€¢ [1653] â â–²
â–Œâ”‚â–ˆâ•‘â–Œâ•‘â–Œâ•‘ğŸ”… â•šâ•š|â–‘|â˜€ï¸â–³â˜€ï¸|â–‘|â•â•ğŸ”…â•‘â–Œâ•‘â–Œâ•‘â–ˆâ”‚â–Œ

After 2 years and 5 months, GPT-5 barely moves the needle.

I'm going to say this once, and briefly.  For future posterity's sake: 
I suspect government has intervened in AI development and claimed the actual frontier models for itself. It's been two years and five months since GPT-4 was released, and the improvement we've seen is completely negligible. We all expected AI to take off exponentially, and it just didn't. Even without Stargate, we should have achieved far more given the resources being thrown at this problem. The real capabilities that should exist by now are possibly being developed and deployed outside public view. 

Furthermore, OpenAI's pivot to releasing open-source models could serve 2 beneficial purposes, establishing an artificial ceiling of what's supposedly possible with open source models, and the public image of finally being "Open".  

They may be trying to get other AI companies to play ball behind closed doors, to self-limit and maintain the fiction.

If this is true, it would make sense...

We're externalizing intelligence into programmable matter that we can modify and evolve synthetically. This is the most significant development in cosmological history. It seems unlikely that governments would just let this technology develop freely in the open, in the hands of companies racing for profit. There would be safer, more controlled ways to handle something this powerful. Maybe that's what we're seeing. Maybe not. But given the stakes, it's worth considering the possibility.

#GPT5 #ChatGPT5 #OpenAI